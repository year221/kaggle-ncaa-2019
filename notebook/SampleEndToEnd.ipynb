{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming ncaa2019 package is installed \n",
    "from ncaa2019 import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default path used C:\\Users\\Huang\\kaggle-ncaa-2019-data\n"
     ]
    }
   ],
   "source": [
    "ds = DataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['city',\n",
       " 'conf',\n",
       " 'conftour',\n",
       " 'gamecity',\n",
       " 'massey',\n",
       " 't_compact_result',\n",
       " 't_detail_result',\n",
       " 't_seed_slot',\n",
       " 't_seed',\n",
       " 't_slot',\n",
       " 'r_compact_result',\n",
       " 'r_detail_result',\n",
       " 'season',\n",
       " 'st_compact_result',\n",
       " 'st_team',\n",
       " 'team',\n",
       " 'coache',\n",
       " 'team_conf',\n",
       " 'team_spelling']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.list_raw_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Score Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_bs = ds.get_raw_data('r_compact_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regular_bs['DayNum'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7fa\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Season</th>        <th class=\"col_heading level0 col1\" >DayNum</th>        <th class=\"col_heading level0 col2\" >WTeamID</th>        <th class=\"col_heading level0 col3\" >WScore</th>        <th class=\"col_heading level0 col4\" >LTeamID</th>        <th class=\"col_heading level0 col5\" >LScore</th>        <th class=\"col_heading level0 col6\" >WLoc</th>        <th class=\"col_heading level0 col7\" >NumOT</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7falevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow0_col0\" class=\"data row0 col0\" >1985</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow0_col1\" class=\"data row0 col1\" >20</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow0_col2\" class=\"data row0 col2\" >1228</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow0_col3\" class=\"data row0 col3\" >81</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow0_col4\" class=\"data row0 col4\" >1328</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow0_col5\" class=\"data row0 col5\" >64</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow0_col6\" class=\"data row0 col6\" >N</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow0_col7\" class=\"data row0 col7\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7falevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow1_col0\" class=\"data row1 col0\" >1985</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow1_col1\" class=\"data row1 col1\" >25</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow1_col2\" class=\"data row1 col2\" >1106</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow1_col3\" class=\"data row1 col3\" >77</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow1_col4\" class=\"data row1 col4\" >1354</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow1_col5\" class=\"data row1 col5\" >70</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow1_col6\" class=\"data row1 col6\" >H</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow1_col7\" class=\"data row1 col7\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7falevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow2_col0\" class=\"data row2 col0\" >1985</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow2_col1\" class=\"data row2 col1\" >25</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow2_col2\" class=\"data row2 col2\" >1112</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow2_col3\" class=\"data row2 col3\" >63</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow2_col4\" class=\"data row2 col4\" >1223</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow2_col5\" class=\"data row2 col5\" >56</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow2_col6\" class=\"data row2 col6\" >H</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow2_col7\" class=\"data row2 col7\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7falevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow3_col0\" class=\"data row3 col0\" >1985</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow3_col1\" class=\"data row3 col1\" >25</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow3_col2\" class=\"data row3 col2\" >1165</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow3_col3\" class=\"data row3 col3\" >70</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow3_col4\" class=\"data row3 col4\" >1432</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow3_col5\" class=\"data row3 col5\" >54</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow3_col6\" class=\"data row3 col6\" >H</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow3_col7\" class=\"data row3 col7\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7falevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow4_col0\" class=\"data row4 col0\" >1985</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow4_col1\" class=\"data row4 col1\" >25</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow4_col2\" class=\"data row4 col2\" >1192</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow4_col3\" class=\"data row4 col3\" >86</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow4_col4\" class=\"data row4 col4\" >1447</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow4_col5\" class=\"data row4 col5\" >74</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow4_col6\" class=\"data row4 col6\" >H</td>\n",
       "                        <td id=\"T_ad199e7a_43a8_11e9_bcb1_dc536007f7farow4_col7\" class=\"data row4 col7\" >0</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x287d02afdd8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regular_bs.head().style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_score_season_hist = pd.concat([\n",
    "    (regular_bs\n",
    "     .assign(relative_score = lambda x: x['WScore'] - x['LScore'],\n",
    "             TeamID = lambda x: x['WTeamID'])\n",
    "     .loc[:,['Season', 'TeamID', 'relative_score']]\n",
    "    ),\n",
    "    (regular_bs\n",
    "     .assign(relative_score = lambda x: x['LScore'] - x['WScore'],\n",
    "             TeamID = lambda x: x['LTeamID'])\n",
    "     .loc[:,['Season', 'TeamID', 'relative_score']]\n",
    "    )],\n",
    "    ignore_index=True,\n",
    "    axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>relative_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Season</th>\n",
       "      <th>TeamID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1985</th>\n",
       "      <th>1102</th>\n",
       "      <td>-5.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>-3.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>7.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>-3.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>7.960000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               relative_score\n",
       "Season TeamID                \n",
       "1985   1102         -5.791667\n",
       "       1103         -3.043478\n",
       "       1104          7.800000\n",
       "       1106         -3.791667\n",
       "       1108          7.960000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_score_season_avg = team_score_season_hist.groupby(['Season', 'TeamID'])[['relative_score']].mean()\n",
    "team_score_season_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['relative_score'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_score_season_avg.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df = ds.get_raw_data('massey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>RankingDayNum</th>\n",
       "      <th>SystemName</th>\n",
       "      <th>TeamID</th>\n",
       "      <th>OrdinalRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>35</td>\n",
       "      <td>SEL</td>\n",
       "      <td>1102</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>35</td>\n",
       "      <td>SEL</td>\n",
       "      <td>1103</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>35</td>\n",
       "      <td>SEL</td>\n",
       "      <td>1104</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>35</td>\n",
       "      <td>SEL</td>\n",
       "      <td>1105</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>35</td>\n",
       "      <td>SEL</td>\n",
       "      <td>1106</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  RankingDayNum SystemName  TeamID  OrdinalRank\n",
       "0    2003             35        SEL    1102          159\n",
       "1    2003             35        SEL    1103          229\n",
       "2    2003             35        SEL    1104           12\n",
       "3    2003             35        SEL    1105          314\n",
       "4    2003             35        SEL    1106          260"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_avg_rank = (rank_df\n",
    "                 .groupby(['Season','TeamID'])[['OrdinalRank']]\n",
    "                 .mean()\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>OrdinalRank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Season</th>\n",
       "      <th>TeamID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2003</th>\n",
       "      <th>1102</th>\n",
       "      <td>144.287500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>182.205000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>27.655502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>305.377500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>243.265000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               OrdinalRank\n",
       "Season TeamID             \n",
       "2003   1102     144.287500\n",
       "       1103     182.205000\n",
       "       1104      27.655502\n",
       "       1105     305.377500\n",
       "       1106     243.265000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_avg_rank.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_records = pd.concat([\n",
    "    (ds\n",
    "     .get_raw_data('t_compact_result')\n",
    "     .assign(GameType='T')\n",
    "    ),\n",
    "    (ds\n",
    "    .get_raw_data('r_compact_result')\n",
    "     .assign(GameType='R')\n",
    "    )],\n",
    "    ignore_index=True,\n",
    "    axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_records_symmetric = pd.concat([\n",
    "    (wl_records\n",
    "     .rename(columns={'WTeamID':'TeamID1',\n",
    "                      'LTeamID':'TeamID2'})\n",
    "     .assign(Winner='Team1')\n",
    "     .loc[:,['Season', 'GameType', 'TeamID1', 'TeamID2', 'Winner']]                     \n",
    "    ),\n",
    "    (wl_records\n",
    "     .rename(columns={'LTeamID':'TeamID1',\n",
    "                      'WTeamID':'TeamID2'})\n",
    "     .assign(Winner='Team2')\n",
    "     .loc[:,['Season', 'GameType', 'TeamID1', 'TeamID2', 'Winner']]                     \n",
    "    )],\n",
    "    ignore_index=True,\n",
    "    axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature and Label Data Frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_label = (\n",
    "    pd.merge(\n",
    "        pd.merge(\n",
    "            wl_records_symmetric,\n",
    "            (team_score_season_avg\n",
    "             .reset_index()\n",
    "             .rename(columns={'TeamID': 'TeamID1', 'relative_score':'Team1_season_score'})\n",
    "            ),\n",
    "            on=['TeamID1', 'Season']\n",
    "        ),       \n",
    "        (team_score_season_avg\n",
    "         .reset_index()\n",
    "         .rename(columns={'TeamID': 'TeamID2', 'relative_score':'Team2_season_score'})\n",
    "        ),\n",
    "        on=['TeamID2', 'Season']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 5 row of feature and label data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_b0230e26_43a8_11e9_803f_dc536007f7fa\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Season</th>        <th class=\"col_heading level0 col1\" >GameType</th>        <th class=\"col_heading level0 col2\" >TeamID1</th>        <th class=\"col_heading level0 col3\" >TeamID2</th>        <th class=\"col_heading level0 col4\" >Winner</th>        <th class=\"col_heading level0 col5\" >Team1_season_score</th>        <th class=\"col_heading level0 col6\" >Team2_season_score</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_b0230e26_43a8_11e9_803f_dc536007f7falevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow0_col0\" class=\"data row0 col0\" >1985</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow0_col1\" class=\"data row0 col1\" >T</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow0_col2\" class=\"data row0 col2\" >1116</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow0_col3\" class=\"data row0 col3\" >1234</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow0_col4\" class=\"data row0 col4\" >Team1</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow0_col5\" class=\"data row0 col5\" >3.63636</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow0_col6\" class=\"data row0 col6\" >10.4667</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b0230e26_43a8_11e9_803f_dc536007f7falevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow1_col0\" class=\"data row1 col0\" >1985</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow1_col1\" class=\"data row1 col1\" >R</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow1_col2\" class=\"data row1 col2\" >1116</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow1_col3\" class=\"data row1 col3\" >1234</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow1_col4\" class=\"data row1 col4\" >Team2</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow1_col5\" class=\"data row1 col5\" >3.63636</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow1_col6\" class=\"data row1 col6\" >10.4667</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b0230e26_43a8_11e9_803f_dc536007f7falevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow2_col0\" class=\"data row2 col0\" >1985</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow2_col1\" class=\"data row2 col1\" >R</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow2_col2\" class=\"data row2 col2\" >1326</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow2_col3\" class=\"data row2 col3\" >1234</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow2_col4\" class=\"data row2 col4\" >Team2</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow2_col5\" class=\"data row2 col5\" >4.67857</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow2_col6\" class=\"data row2 col6\" >10.4667</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b0230e26_43a8_11e9_803f_dc536007f7falevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow3_col0\" class=\"data row3 col0\" >1985</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow3_col1\" class=\"data row3 col1\" >R</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow3_col2\" class=\"data row3 col2\" >1326</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow3_col3\" class=\"data row3 col3\" >1234</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow3_col4\" class=\"data row3 col4\" >Team2</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow3_col5\" class=\"data row3 col5\" >4.67857</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow3_col6\" class=\"data row3 col6\" >10.4667</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b0230e26_43a8_11e9_803f_dc536007f7falevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow4_col0\" class=\"data row4 col0\" >1985</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow4_col1\" class=\"data row4 col1\" >R</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow4_col2\" class=\"data row4 col2\" >1228</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow4_col3\" class=\"data row4 col3\" >1234</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow4_col4\" class=\"data row4 col4\" >Team1</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow4_col5\" class=\"data row4 col5\" >10.871</td>\n",
       "                        <td id=\"T_b0230e26_43a8_11e9_803f_dc536007f7farow4_col6\" class=\"data row4 col6\" >10.4667</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x287d61ad390>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_label.head().style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Test Data\n",
    "We only use season average WL difference as the feature.\n",
    "All regular season result + Playoff before 2011 are available for training\n",
    "Playoff after 2011 including 2011 are set aside as test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_df_split(feature_label):\n",
    "    train_data = feature_label.loc[(feature_label['Season']<2011) |\n",
    "                                   (feature_label['GameType']=='R'), :]\n",
    "    test_data = feature_label.loc[(feature_label['Season']>=2011) &\n",
    "                                  (feature_label['GameType']=='T'), :]\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def train_test_split(feature_label):\n",
    "    train_df, test_df = train_test_df_split(feature_label)\n",
    "    X_train = train_df[['Team1_season_score','Team2_season_score']].values\n",
    "    y_train = train_df['Winner'].apply(lambda x: 1 if x=='Team1' else 0).values\n",
    "    X_test = test_df[['Team1_season_score','Team2_season_score']].values\n",
    "    y_test = test_df['Winner'].apply(lambda x: 1 if x=='Team1' else 0).values    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(315474, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feature_label)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top of train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train:\n",
      "[[  3.63636364  10.46666667]\n",
      " [  3.63636364  10.46666667]\n",
      " [  4.67857143  10.46666667]\n",
      " ...\n",
      " [-13.71875      0.26666667]\n",
      " [-13.71875      0.26666667]\n",
      " [-15.26666667   0.26666667]]\n",
      "y_train\n",
      "[1 0 0 ... 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "X_train:\n",
    "{X_train}\n",
    "y_train\n",
    "{y_train}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "We apply the logistc regression to test the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\app\\conda\\envs\\p37web\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=False,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(fit_intercept=False)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_score(y_value, p_predict):\n",
    "    score = -(np.sum(np.log(p_predict[y_value==1])) + np.sum(np.log(1-p_predict[y_value==0])))/len(y_value)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_prob(clf, X):\n",
    "    prob_class = clf.predict_proba(X)\n",
    "    prob = prob_class[:,1]\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KL Score for dummy estimator: 0.6931471805599453\n",
      "KL Score in training data: 0.5291835615488899\n",
      "KL Score in testing data: 0.6194114258739689\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "f\"\"\"\n",
    "KL Score for dummy estimator: {KL_score(y_test, np.repeat(0.5, len(y_test)))}\n",
    "KL Score in training data: {KL_score(y_train, predict_prob(clf, X_train))}\n",
    "KL Score in testing data: {KL_score(y_test, predict_prob(clf, X_test))}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# only use post season scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>TeamID1</th>\n",
       "      <th>TeamID2</th>\n",
       "      <th>Winner</th>\n",
       "      <th>Team1_season_score</th>\n",
       "      <th>Team2_season_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GameType</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>312178</td>\n",
       "      <td>312178</td>\n",
       "      <td>312178</td>\n",
       "      <td>312178</td>\n",
       "      <td>312178</td>\n",
       "      <td>312178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>4368</td>\n",
       "      <td>4368</td>\n",
       "      <td>4368</td>\n",
       "      <td>4368</td>\n",
       "      <td>4368</td>\n",
       "      <td>4368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Season  TeamID1  TeamID2  Winner  Team1_season_score  \\\n",
       "GameType                                                         \n",
       "R         312178   312178   312178  312178              312178   \n",
       "T           4368     4368     4368    4368                4368   \n",
       "\n",
       "          Team2_season_score  \n",
       "GameType                      \n",
       "R                     312178  \n",
       "T                       4368  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_label.groupby('GameType').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_df_split(feature_label):\n",
    "    train_data = feature_label.loc[(feature_label['Season']<2011) &\n",
    "                                   (feature_label['GameType']=='T'), :]\n",
    "    test_data = feature_label.loc[(feature_label['Season']>=2011) &\n",
    "                                  (feature_label['GameType']=='T'), :]\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def train_test_split(feature_label):\n",
    "    train_df, test_df = train_test_df_split(feature_label)\n",
    "    X_train = train_df[['Team1_season_score','Team2_season_score']].values\n",
    "    y_train = train_df['Winner'].apply(lambda x: 1 if x=='Team1' else 0).values\n",
    "    X_test = test_df[['Team1_season_score','Team2_season_score']].values\n",
    "    y_test = test_df['Winner'].apply(lambda x: 1 if x=='Team1' else 0).values    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feature_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3296, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\app\\conda\\envs\\p37web\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=False,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(fit_intercept=False)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KL Score for dummy estimator: 0.6931471805599453\n",
      "KL Score in training data: 0.5973824388937066\n",
      "KL Score in testing data: 0.6180925730126637\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "f\"\"\"\n",
    "KL Score for dummy estimator: {KL_score(y_test, np.repeat(0.5, len(y_test)))}\n",
    "KL Score in training data: {KL_score(y_train, predict_prob(clf, X_train))}\n",
    "KL Score in testing data: {KL_score(y_test, predict_prob(clf, X_test))}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'accuracy', 'roc_auc', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'brier_score_loss', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\app\\conda\\envs\\p37web\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv='warn', dual=False,\n",
       "           fit_intercept=False, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='warn', n_jobs=None, penalty='l2',\n",
       "           random_state=None, refit=True, scoring='neg_log_loss',\n",
       "           solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegressionCV(fit_intercept=False,scoring =  'neg_log_loss')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KL Score for dummy estimator: 0.6931471805599453\n",
      "KL Score in training data: 0.5973984453130364\n",
      "KL Score in testing data: 0.6179979325204425\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "f\"\"\"\n",
    "KL Score for dummy estimator: {KL_score(y_test, np.repeat(0.5, len(y_test)))}\n",
    "KL Score in training data: {KL_score(y_train, predict_prob(clf, X_train))}\n",
    "KL Score in testing data: {KL_score(y_test, predict_prob(clf, X_test))}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank + Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_label = (\n",
    "    pd.merge(\n",
    "        pd.merge(\n",
    "            wl_records_symmetric,\n",
    "            (team_score_season_avg\n",
    "             .reset_index()\n",
    "             .rename(columns={'TeamID': 'TeamID1', 'relative_score':'Team1_season_score'})\n",
    "            ),\n",
    "            on=['TeamID1', 'Season']\n",
    "        ),       \n",
    "        (team_score_season_avg\n",
    "         .reset_index()\n",
    "         .rename(columns={'TeamID': 'TeamID2', 'relative_score':'Team2_season_score'})\n",
    "        ),\n",
    "        on=['TeamID2', 'Season']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_rank = pd.merge(team_score_season_avg.reset_index(), team_avg_rank.reset_index(), on=['Season', 'TeamID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_label = (\n",
    "    pd.merge(\n",
    "        pd.merge(\n",
    "            wl_records_symmetric,\n",
    "            (score_rank             \n",
    "             .rename(columns={'TeamID': 'TeamID1', 'relative_score':'Team1_season_score', 'OrdinalRank':'Team1_OrdinalRank'\n",
    "                             })\n",
    "            ),\n",
    "            on=['TeamID1', 'Season']\n",
    "        ),       \n",
    "        (score_rank         \n",
    "         .rename(columns={'TeamID': 'TeamID2', 'relative_score':'Team2_season_score', 'OrdinalRank':'Team2_OrdinalRank'})\n",
    "        ),\n",
    "        on=['TeamID2', 'Season']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_df_split(feature_label):\n",
    "    train_data = feature_label.loc[(feature_label['Season']<2011) |\n",
    "                                   (feature_label['GameType']=='R'), :]\n",
    "    test_data = feature_label.loc[(feature_label['Season']>=2011) &\n",
    "                                  (feature_label['GameType']=='T'), :]\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def train_test_split(feature_label):\n",
    "    train_df, test_df = train_test_df_split(feature_label)\n",
    "    X_train = train_df[['Team1_season_score','Team2_season_score','Team1_OrdinalRank','Team2_OrdinalRank']].values\n",
    "    y_train = train_df['Winner'].apply(lambda x: 1 if x=='Team1' else 0).values\n",
    "    X_test = test_df[['Team1_season_score','Team2_season_score','Team1_OrdinalRank','Team2_OrdinalRank']].values\n",
    "    y_test = test_df['Winner'].apply(lambda x: 1 if x=='Team1' else 0).values    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feature_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\app\\conda\\envs\\p37web\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('SS', StandardScaler(copy=True, with_mean=True, with_std=True)), ('LR', LogisticRegressionCV(Cs=10, class_weight=None, cv='warn', dual=False,\n",
       "           fit_intercept=False, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='warn', n_jobs=None, penalty='l2',\n",
       "           random_state=None, refit=True, scoring='neg_log_loss',\n",
       "           solver='lbfgs', tol=0.0001, verbose=0))])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = pipeline.Pipeline([('SS', preprocessing.StandardScaler()),\n",
    "                ('LR', LogisticRegressionCV(fit_intercept=False,scoring =  'neg_log_loss'))])\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22991145, -0.22981372, -1.33141786,  1.33152004]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.named_steps['LR'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KL Score for dummy estimator: 0.6931471805599453\n",
      "KL Score in training data: 0.4948252308285958\n",
      "KL Score in testing data: 0.5736330128092295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "f\"\"\"\n",
    "KL Score for dummy estimator: {KL_score(y_test, np.repeat(0.5, len(y_test)))}\n",
    "KL Score in training data: {KL_score(y_train, predict_prob(clf, X_train))}\n",
    "KL Score in testing data: {KL_score(y_test, predict_prob(clf, X_test))}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_df_split(feature_label):\n",
    "    train_data = feature_label.loc[(feature_label['Season']<2011) *\n",
    "                                   (feature_label['GameType']=='T'), :]\n",
    "    test_data = feature_label.loc[(feature_label['Season']>=2011) &\n",
    "                                  (feature_label['GameType']=='T'), :]\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def train_test_split(feature_label):\n",
    "    train_df, test_df = train_test_df_split(feature_label)\n",
    "    X_train = train_df[['Team1_season_score','Team2_season_score','Team1_OrdinalRank','Team2_OrdinalRank']].values\n",
    "    y_train = train_df['Winner'].apply(lambda x: 1 if x=='Team1' else 0).values\n",
    "    X_test = test_df[['Team1_season_score','Team2_season_score','Team1_OrdinalRank','Team2_OrdinalRank']].values\n",
    "    y_test = test_df['Winner'].apply(lambda x: 1 if x=='Team1' else 0).values    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\app\\conda\\envs\\p37web\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:183: UserWarning: evaluating in Python space because the '*' operator is not supported by numexpr for the bool dtype, use '&' instead\n",
      "  .format(op=op_str, alt_op=unsupported[op_str]))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feature_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\app\\conda\\envs\\p37web\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('SS', StandardScaler(copy=True, with_mean=True, with_std=True)), ('LR', LogisticRegressionCV(Cs=10, class_weight=None, cv='warn', dual=False,\n",
       "           fit_intercept=False, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='warn', n_jobs=None, penalty='l2',\n",
       "           random_state=None, refit=True, scoring='neg_log_loss',\n",
       "           solver='lbfgs', tol=0.0001, verbose=0))])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = pipeline.Pipeline([('SS', preprocessing.StandardScaler()),\n",
    "                ('LR', LogisticRegressionCV(fit_intercept=False,scoring =  'neg_log_loss'))])\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KL Score for dummy estimator: 0.6931471805599453\n",
      "KL Score in training data: 0.49633304853756893\n",
      "KL Score in testing data: 0.5769814327460678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "f\"\"\"\n",
    "KL Score for dummy estimator: {KL_score(y_test, np.repeat(0.5, len(y_test)))}\n",
    "KL Score in training data: {KL_score(y_train, predict_prob(clf, X_train))}\n",
    "KL Score in testing data: {KL_score(y_test, predict_prob(clf, X_test))}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_df_split(feature_label):\n",
    "    train_data = feature_label.loc[(feature_label['Season']<2011) |\n",
    "                                   (feature_label['GameType']=='R'), :]\n",
    "    test_data = feature_label.loc[(feature_label['Season']>=2011) &\n",
    "                                  (feature_label['GameType']=='T'), :]\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def train_test_split(feature_label):\n",
    "    train_df, test_df = train_test_df_split(feature_label)\n",
    "    X_train = train_df[['Team1_OrdinalRank','Team2_OrdinalRank']].values\n",
    "    y_train = train_df['Winner'].apply(lambda x: 1 if x=='Team1' else 0).values\n",
    "    X_test = test_df[['Team1_OrdinalRank','Team2_OrdinalRank']].values\n",
    "    y_test = test_df['Winner'].apply(lambda x: 1 if x=='Team1' else 0).values    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feature_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_df_split(feature_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>TeamID1</th>\n",
       "      <th>TeamID2</th>\n",
       "      <th>Team1_season_score</th>\n",
       "      <th>Team1_OrdinalRank</th>\n",
       "      <th>Team2_season_score</th>\n",
       "      <th>Team2_OrdinalRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Season</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.007960</td>\n",
       "      <td>0.047904</td>\n",
       "      <td>-0.007960</td>\n",
       "      <td>0.047904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TeamID1</th>\n",
       "      <td>-0.000083</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004305</td>\n",
       "      <td>0.066632</td>\n",
       "      <td>-0.092424</td>\n",
       "      <td>0.028389</td>\n",
       "      <td>-0.047744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TeamID2</th>\n",
       "      <td>-0.000083</td>\n",
       "      <td>0.004305</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028389</td>\n",
       "      <td>-0.047744</td>\n",
       "      <td>0.066632</td>\n",
       "      <td>-0.092424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Team1_season_score</th>\n",
       "      <td>-0.007960</td>\n",
       "      <td>0.066632</td>\n",
       "      <td>0.028389</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.871584</td>\n",
       "      <td>0.110839</td>\n",
       "      <td>-0.216249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Team1_OrdinalRank</th>\n",
       "      <td>0.047904</td>\n",
       "      <td>-0.092424</td>\n",
       "      <td>-0.047744</td>\n",
       "      <td>-0.871584</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.216249</td>\n",
       "      <td>0.381897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Team2_season_score</th>\n",
       "      <td>-0.007960</td>\n",
       "      <td>0.028389</td>\n",
       "      <td>0.066632</td>\n",
       "      <td>0.110839</td>\n",
       "      <td>-0.216249</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.871584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Team2_OrdinalRank</th>\n",
       "      <td>0.047904</td>\n",
       "      <td>-0.047744</td>\n",
       "      <td>-0.092424</td>\n",
       "      <td>-0.216249</td>\n",
       "      <td>0.381897</td>\n",
       "      <td>-0.871584</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Season   TeamID1   TeamID2  Team1_season_score  \\\n",
       "Season              1.000000 -0.000083 -0.000083           -0.007960   \n",
       "TeamID1            -0.000083  1.000000  0.004305            0.066632   \n",
       "TeamID2            -0.000083  0.004305  1.000000            0.028389   \n",
       "Team1_season_score -0.007960  0.066632  0.028389            1.000000   \n",
       "Team1_OrdinalRank   0.047904 -0.092424 -0.047744           -0.871584   \n",
       "Team2_season_score -0.007960  0.028389  0.066632            0.110839   \n",
       "Team2_OrdinalRank   0.047904 -0.047744 -0.092424           -0.216249   \n",
       "\n",
       "                    Team1_OrdinalRank  Team2_season_score  Team2_OrdinalRank  \n",
       "Season                       0.047904           -0.007960           0.047904  \n",
       "TeamID1                     -0.092424            0.028389          -0.047744  \n",
       "TeamID2                     -0.047744            0.066632          -0.092424  \n",
       "Team1_season_score          -0.871584            0.110839          -0.216249  \n",
       "Team1_OrdinalRank            1.000000           -0.216249           0.381897  \n",
       "Team2_season_score          -0.216249            1.000000          -0.871584  \n",
       "Team2_OrdinalRank            0.381897           -0.871584           1.000000  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165106, 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\app\\conda\\envs\\p37web\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv='warn', dual=False,\n",
       "           fit_intercept=False, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='warn', n_jobs=None, penalty='l2',\n",
       "           random_state=None, refit=True, scoring='neg_log_loss',\n",
       "           solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegressionCV(fit_intercept=False,scoring =  'neg_log_loss')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`\n",
      "KL Score for dummy estimator: 0.6931471805599453\n",
      "KL Score in training data: 0.4948252308285958\n",
      "KL Score in testing data: 0.5736330128092295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "f\"\"\"`\n",
    "KL Score for dummy estimator: {KL_score(y_test, np.repeat(0.5, len(y_test)))}\n",
    "KL Score in training data: {KL_score(y_train, predict_prob(clf, X_train))}\n",
    "KL Score in testing data: {KL_score(y_test, predict_prob(clf, X_test))}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_df_split(feature_label):\n",
    "    train_data = feature_label.loc[(feature_label['Season']<2011) &\n",
    "                                   (feature_label['GameType']=='T'), :]\n",
    "    test_data = feature_label.loc[(feature_label['Season']>=2011) &\n",
    "                                  (feature_label['GameType']=='T'), :]\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def train_test_split(feature_label):\n",
    "    train_df, test_df = train_test_df_split(feature_label)\n",
    "    X_train = train_df[['Team1_OrdinalRank','Team2_OrdinalRank']].values\n",
    "    y_train = train_df['Winner'].apply(lambda x: 1 if x=='Team1' else 0).values\n",
    "    X_test = test_df[['Team1_OrdinalRank','Team2_OrdinalRank']].values\n",
    "    y_test = test_df['Winner'].apply(lambda x: 1 if x=='Team1' else 0).values    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feature_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[241.37      , 236.2175    ],\n",
       "       [241.37      ,   9.41627907],\n",
       "       [ 31.08726415,   9.41627907],\n",
       "       ...,\n",
       "       [  3.95454545, 146.05320814],\n",
       "       [ 38.87575758, 113.44444444],\n",
       "       [ 16.92898551, 109.01095462]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 2)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\app\\conda\\envs\\p37web\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv='warn', dual=False,\n",
       "           fit_intercept=False, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='warn', n_jobs=None, penalty='l2',\n",
       "           random_state=None, refit=True, scoring='neg_log_loss',\n",
       "           solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegressionCV(fit_intercept=False,scoring =  'neg_log_loss')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`\n",
      "KL Score for dummy estimator: 0.6931471805599453\n",
      "KL Score in training data: 0.5309060958025951\n",
      "KL Score in testing data: 0.5855290376895113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "f\"\"\"`\n",
    "KL Score for dummy estimator: {KL_score(y_test, np.repeat(0.5, len(y_test)))}\n",
    "KL Score in training data: {KL_score(y_train, predict_prob(clf, X_train))}\n",
    "KL Score in testing data: {KL_score(y_test, predict_prob(clf, X_test))}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation\n",
    "The performance in rank only seems to be the same as combining diff score with rank, and is better than diff score only. We now check the correlation between rank and diff-score, which shows a very strong correlation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative_score</th>\n",
       "      <th>OrdinalRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>relative_score</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.86982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrdinalRank</th>\n",
       "      <td>-0.86982</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                relative_score  OrdinalRank\n",
       "relative_score         1.00000     -0.86982\n",
       "OrdinalRank           -0.86982      1.00000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_rank[['relative_score','OrdinalRank']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative_score</th>\n",
       "      <th>OrdinalRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>relative_score</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.88029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrdinalRank</th>\n",
       "      <td>-0.88029</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                relative_score  OrdinalRank\n",
       "relative_score         1.00000     -0.88029\n",
       "OrdinalRank           -0.88029      1.00000"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_rank[['relative_score','OrdinalRank']].corr('spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
